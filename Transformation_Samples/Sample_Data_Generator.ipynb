{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec8bc82-eec4-489f-a6a4-b057c61e80b8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1 Generate Synthetic Site Data with Brands and Reg ..."
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, concat, lit, floor, rand, round, expr\n",
    "\n",
    "# Create site_id column\n",
    "df = spark.range(1, 51).withColumnRenamed(\"id\", \"site_id\")\n",
    "\n",
    "# Brand assignment: 'Shell' ~20%, others ~20% each\n",
    "brand_expr = when(col(\"site_id\") <= 10, lit(\"Shell\")) \\\n",
    "    .when(col(\"site_id\") <= 20, lit(\"Aral\")) \\\n",
    "    .when(col(\"site_id\") <= 30, lit(\"Esso\")) \\\n",
    "    .when(col(\"site_id\") <= 40, lit(\"Total\")) \\\n",
    "    .otherwise(lit(\"Jet\"))\n",
    "\n",
    "df = df.withColumn(\"brand\", brand_expr)\n",
    "\n",
    "# site_type logic\n",
    "df = df.withColumn(\"site_type\", when(col(\"brand\") == \"Shell\", lit(\"Internal\")).otherwise(lit(\"Competitor\")))\n",
    "\n",
    "# site_name\n",
    "df = df.withColumn(\"site_name\", concat(col(\"brand\"), lit(\" Station \"), col(\"site_id\")))\n",
    "\n",
    "# region random assignment (fix: use expr with array and cast index)\n",
    "df = df.withColumn(\"region\", expr(\"array('DE-BE', 'DE-BY', 'DE-NW', 'DE-HE')[cast(floor(rand() * 4) as int)]\"))\n",
    "\n",
    "# zone_type random assignment (fix: use expr with array and cast index)\n",
    "df = df.withColumn(\"zone_type\", expr(\"array('Highway', 'Urban', 'Rural')[cast(floor(rand() * 3) as int)]\"))\n",
    "\n",
    "# latitude random float between 47.0 and 55.0\n",
    "df = df.withColumn(\"latitude\", round(lit(47.0) + rand() * lit(8.0), 6))\n",
    "\n",
    "# longitude random float between 5.0 and 15.0\n",
    "df_sites = df.withColumn(\"longitude\", round(lit(5.0) + rand() * lit(10.0), 6))\n",
    "\n",
    "# Display schema to confirm site_id is Integer\n",
    "df_sites.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a74654-63ff-4c5a-b913-4d93fadced54",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2 Create Product Master DataFrame with Fuel Grades"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType(), False),\n",
    "    StructField(\"category\", StringType(), False),\n",
    "    StructField(\"product_name\", StringType(), False),\n",
    "    StructField(\"grade\", StringType(), False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1, 'Petrol', 'Shell Super FuelSave 95', 'Standard'),\n",
    "    (2, 'Petrol', 'Shell V-Power Racing 100', 'Premium'),\n",
    "    (3, 'Diesel', 'Shell Diesel FuelSave', 'Standard'),\n",
    "    (4, 'Diesel', 'Shell V-Power Diesel', 'Premium'),\n",
    "    (5, 'Petrol', 'Competitor Unleaded 95', 'Standard'),\n",
    "    (6, 'Diesel', 'Competitor Diesel', 'Standard')\n",
    "]\n",
    "\n",
    "df_product_master = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be6fb46-036e-4ffa-98c3-f15978edb88b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4 Create Competitor Mapping with Strategy Assignme ..."
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, rand, expr, monotonically_increasing_id\n",
    "\n",
    "# Step A: Create Product Rules\n",
    "product_rules_data = [\n",
    "    Row(internal_product_id=1, competitor_product_id=5),\n",
    "    Row(internal_product_id=2, competitor_product_id=5),\n",
    "    Row(internal_product_id=3, competitor_product_id=6),\n",
    "    Row(internal_product_id=4, competitor_product_id=6)\n",
    "]\n",
    "df_product_rules = spark.createDataFrame(product_rules_data)\n",
    "\n",
    "# Step B: Create Site Links\n",
    "df_internal_sites = df.filter(col(\"site_type\") == \"Internal\").select(col(\"site_id\").alias(\"internal_site_id\"))\n",
    "df_competitor_sites = df.filter(col(\"site_type\") == \"Competitor\").select(col(\"site_id\").alias(\"competitor_site_id\"))\n",
    "df_site_links = df_internal_sites.crossJoin(df_competitor_sites)\n",
    "\n",
    "w = Window.partitionBy(\"internal_site_id\").orderBy(rand())\n",
    "df_site_links = df_site_links.withColumn(\"rn\", expr(\"row_number() over (partition by internal_site_id order by rand())\"))\n",
    "df_site_links = df_site_links.filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "# Step C: Generate Full Mapping\n",
    "df_full_mapping = df_site_links.crossJoin(df_product_rules)\n",
    "\n",
    "# Step D: Add Strategy and mapping_id\n",
    "strategy_expr = expr(\"array('MATCH', 'MINUS_1_CENT', 'PLUS_2_CENT')[cast(floor(rand() * 3) as int)]\")\n",
    "df_competitor_mapping = df_full_mapping.withColumn(\"strategy\", strategy_expr)\n",
    "df_competitor_mapping = df_competitor_mapping.withColumn(\"mapping_id\", monotonically_increasing_id())\n",
    "\n",
    "df_competitor_mapping = df_competitor_mapping.select(\n",
    "    \"mapping_id\",\n",
    "    \"internal_site_id\",\n",
    "    \"internal_product_id\",\n",
    "    \"competitor_site_id\",\n",
    "    \"competitor_product_id\",\n",
    "    \"strategy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52035282-10ba-4cf5-b5bd-b873870805c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3 Generate Pricing Feed with Timestamped Data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sequence, explode, to_timestamp, lit, col, monotonically_increasing_id, round, rand, expr, when\n",
    "\n",
    "# Time DataFrame: 15-min intervals from '2024-01-01 00:00:00' to '2024-01-01 23:45:00'\n",
    "df_time = spark.createDataFrame([(\"2024-01-01 00:00:00\", \"2024-01-01 23:45:00\")], [\"start\", \"end\"]) \\\n",
    "    .withColumn(\"timestamps\", sequence(\n",
    "        to_timestamp(col(\"start\")),\n",
    "        to_timestamp(col(\"end\")),\n",
    "        expr(\"interval 15 minutes\")\n",
    "    )) \\\n",
    "    .select(explode(col(\"timestamps\")).alias(\"timestamp\"))\n",
    "\n",
    "# Cross join sites, products, and time\n",
    "df_pricing_feed = df.crossJoin(df_product_master).crossJoin(df_time)\n",
    "\n",
    "# Price calculation\n",
    "df_pricing_feed = df_pricing_feed.withColumn(\n",
    "    \"price\",\n",
    "    round(\n",
    "        lit(1.70) +\n",
    "        when(col(\"grade\") == \"Premium\", lit(0.10)).otherwise(lit(0.0)) +\n",
    "        when(col(\"zone_type\") == \"Highway\", lit(0.05)).otherwise(lit(0.0)) +\n",
    "        (rand() * lit(0.10) - lit(0.05)),\n",
    "        2\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add price_id\n",
    "df_pricing_feed = df_pricing_feed.withColumn(\"price_id\", monotonically_increasing_id().cast(\"long\"))\n",
    "\n",
    "# Select required columns\n",
    "df_pricing_feed = df_pricing_feed.select(\n",
    "    \"price_id\",\n",
    "    \"site_id\",\n",
    "    \"product_id\",\n",
    "    \"timestamp\",\n",
    "    \"price\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df0929a-8694-4f2b-9e31-024a82cf4afb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 5 Generate Transaction Data with Internal Site Vol ..."
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, round, rand, floor, col\n",
    "\n",
    "# Filter to Internal sites\n",
    "df_internal_sites = df.filter(col(\"site_type\") == \"Internal\").select(\"site_id\")\n",
    "df_transactions = df_pricing_feed.join(df_internal_sites, \"site_id\")\n",
    "\n",
    "# Sample 10% of rows\n",
    "df_transactions = df_transactions.sample(fraction=0.1)\n",
    "\n",
    "# Add volume (random integer between 10 and 80)\n",
    "df_transactions = df_transactions.withColumn(\n",
    "    \"volume\",\n",
    "    (floor(rand() * 71) + 10).cast(\"double\")\n",
    ")\n",
    "\n",
    "# Calculate amount\n",
    "df_transactions = df_transactions.withColumn(\n",
    "    \"amount\",\n",
    "    round(col(\"volume\") * col(\"price\"), 2)\n",
    ")\n",
    "\n",
    "# Add transaction_id\n",
    "df_transactions = df_transactions.withColumn(\n",
    "    \"transaction_id\",\n",
    "    monotonically_increasing_id().cast(\"long\")\n",
    ")\n",
    "\n",
    "# Select and order columns\n",
    "df_transactions = df_transactions.select(\n",
    "    \"transaction_id\",\n",
    "    col(\"site_id\").cast(\"long\"),\n",
    "    col(\"product_id\").cast(\"long\"),\n",
    "    \"timestamp\",\n",
    "    col(\"volume\").cast(\"double\"),\n",
    "    col(\"amount\").cast(\"double\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b1ef21-c7b7-4510-bccc-fc40c23abb7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(df_sites)\n",
    "# display(df_product_master)\n",
    "# display(df_competitor_mapping)\n",
    "# display(df_pricing_feed)\n",
    "# display(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe3e26b-ae7d-4eb4-8cb0-7960daaf777f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12 Write DataFrames to Parquet"
    }
   },
   "outputs": [],
   "source": [
    "# df_sites.write.parquet(\"/Volumes/main/default/volume/FuelData/Sites\", mode=\"overwrite\")\n",
    "# df_product_master.write.parquet(\"/Volumes/main/default/volume/FuelData/ProductMaster\", mode=\"overwrite\")\n",
    "# df_competitor_mapping.write.parquet(\"/Volumes/main/default/volume/FuelData/CompetitorMapping\", mode=\"overwrite\")\n",
    "# df_pricing_feed.write.parquet(\"/Volumes/main/default/volume/FuelData/PricingFeed\", mode=\"overwrite\")\n",
    "# df_transactions.write.parquet(\"/Volumes/main/default/volume/FuelData/Transactions\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788f0e32-ff2f-4b73-b9a1-0727f500a65b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"/Volumes/main/default/volume/FuelData/Sites\")\n",
    "print(\"/Volumes/main/default/volume/FuelData/ProductMaster\")\n",
    "print(\"/Volumes/main/default/volume/FuelData/CompetitorMapping\")\n",
    "print(\"/Volumes/main/default/volume/FuelData/PricingFeed\")\n",
    "print(\"/Volumes/main/default/volume/FuelData/Transactions\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6056749587013335,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Sample_Data_Generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
